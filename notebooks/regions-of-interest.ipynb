{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConcentriqÂ® Embeddings with Region of Interest targeting\n",
    "\n",
    "In this notebook, we will illustrate how to:\n",
    "- Request and download image thumbnails\n",
    "- Define region(s) of interest over which to request embeddings\n",
    "- Visualize the resulting embedded patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.client import ClientWrapper as Client\n",
    "\n",
    "MODEL = \"1aurent/swin_tiny_patch4_window7_224.CTransPath\"\n",
    "PATCH_SIZE = 224\n",
    "MPP = 1\n",
    "\n",
    "email = os.getenv(\"CONCENTRIQ_EMAIL\")\n",
    "pwd = os.getenv(\"CONCENTRIQ_PASSWORD\")\n",
    "endpoint = os.getenv(\"CONCENTRIQ_ENDPOINT_URL\")\n",
    "\n",
    "# To use CPU instead of GPU, set `device` parameter to `\"cpu\"`\n",
    "ce_api_client = Client(url=endpoint, email=email, password=pwd, device='cpu')\n",
    "ce_api_client.token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch a thumbnail of a slide\n",
    "Concentriq embeddings will produce thumbnail images of slides at 7 microns per pixel. We can then use these to select regions of interest (here we'll focus on tissue) to be embedded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 6453\n",
    "image_ids = [image_id] # A sinlge image from the IMPRESS Dataset\n",
    "ticket_id = ce_api_client.thumbnail_images(ids=image_ids)\n",
    "print(ticket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails = ce_api_client.get_thumbnails(ticket_id, load_thumbnails=True, polling_interval_seconds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Tissue using the thumbnail\n",
    "\n",
    "Here we'll use a simple thresholding method (Otsu) to identify tissue regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tissue_otsu(thumbnail, thumbnail_mpp=7, embedding_mpp=2, patch_size=224):\n",
    "    \"\"\"\n",
    "    Simple tissue detection using Otsu thresholding\n",
    "    \n",
    "    Args:\n",
    "    thumbnail: np.array\n",
    "        Thumbnail image\n",
    "    thumbnail_mpp: float\n",
    "        Microns per pixel of the thumbnail. The default is 7, which is what Concentriq Embeddings supplies.\n",
    "    embedding_mpp: float\n",
    "        Microns per pixel of the embedding\n",
    "    patch_size: int\n",
    "        Patch size in pixels -- This is model-dependent, default is 224. \n",
    "        \n",
    "    Returns:\n",
    "    regions: list\n",
    "        List of dictionaries containing x, y, width, and height of the detected tissue regions\n",
    "    \"\"\"\n",
    "    # convert to gray scale\n",
    "    img = cv2.cvtColor(thumbnail, cv2.COLOR_BGR2GRAY)\n",
    "    otsu_threshold, res = cv2.threshold(\n",
    "        img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,\n",
    "    )\n",
    "    print(\"Obtained threshold: \", otsu_threshold)\n",
    "\n",
    "    # remove noise\n",
    "    raw_mask = (res==0).astype(np.uint8)\n",
    "    noise_removal_kernel = np.ones((3, 3), np.uint8)\n",
    "    noise_mask = cv2.morphologyEx(raw_mask, cv2.MORPH_OPEN, noise_removal_kernel)\n",
    "\n",
    "    # fill small gaps\n",
    "    fill_gaps_kernel = np.ones((100, 100), np.uint8)\n",
    "    filled_mask = cv2.morphologyEx(noise_mask, cv2.MORPH_CLOSE, fill_gaps_kernel)\n",
    "\n",
    "    thumbnail_patch_size = round(patch_size * embedding_mpp / thumbnail_mpp)\n",
    "    grid_x = np.arange(0, thumbnail.shape[1] // thumbnail_patch_size).astype(int)\n",
    "    grid_y = np.arange(0, thumbnail.shape[0] // thumbnail_patch_size).astype(int)\n",
    "    regions = []\n",
    "    ratio = patch_size * embedding_mpp / thumbnail_mpp\n",
    "    for x in grid_x:\n",
    "        for y in grid_y:\n",
    "            x_start = round(x * ratio)\n",
    "            y_start = round(y * ratio)\n",
    "            x_end = round(x_start + thumbnail_patch_size)\n",
    "            y_end = round(y_start + thumbnail_patch_size)\n",
    "            patch = filled_mask[y_start:y_end, x_start:x_end].sum()\n",
    "            if np.sum(patch) > 0:\n",
    "                cv2.rectangle(thumbnail, (x_start, y_start), (x_end, y_end), (0, 255, 0), 2)\n",
    "                regions.append({\n",
    "                    \"x\": int(x_start),\n",
    "                    \"y\": int(y_start),\n",
    "                    \"width\": int(thumbnail_patch_size),\n",
    "                    \"height\": int(thumbnail_patch_size),\n",
    "                })\n",
    "    plt.imshow(thumbnail)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail_img = thumbnails[\"thumbnails\"][0][\"thumbnail\"].copy()\n",
    "bbs = simple_tissue_otsu(thumbnail_img, patch_size=PATCH_SIZE, embedding_mpp=MPP)\n",
    "print(f\"Segmented tissue into {len(bbs)} bounding box regions of interest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit a job containing regions of interest to be embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_id = ce_api_client.embed_roi(image_id=image_id, regions=bbs, mpp=MPP, model=MODEL)\n",
    "print(ticket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = ce_api_client.get_embeddings(ticket_id, polling_interval_seconds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we used the correct patch size for the model\n",
    "assert embeddings[\"images\"][0][\"patch_size\"] == PATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the resulting embedded patches\n",
    "Here we'll use the Y_X grid locations of the embedings in conjunction with the embedding mpp that we requested to map the embedded patches onto the thumbnail and confirm that the locations are what we requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_keys = embeddings[\"images\"][0][\"embedding\"].keys()\n",
    "emb_locs = np.array([[int(coord) for coord in k.split(\"_\")] for k in emb_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail = thumbnail_img.copy()\n",
    "mpp = embeddings[\"images\"][0][\"mpp\"]\n",
    "patch_size = embeddings[\"images\"][0][\"patch_size\"]\n",
    "thumbnail_mpp = 7\n",
    "thumbnail_patch_size = round(patch_size * mpp / thumbnail_mpp)\n",
    "mircons_per_patch = patch_size * mpp\n",
    "print(thumbnail_patch_size)\n",
    "w, h = thumbnail_patch_size, thumbnail_patch_size\n",
    "for y, x in emb_locs:\n",
    "    x_thumb = round(x * mircons_per_patch / thumbnail_mpp)\n",
    "    y_thumb = round(y * mircons_per_patch / thumbnail_mpp)\n",
    "    cv2.rectangle(thumbnail, (x_thumb, y_thumb), (x_thumb+w, y_thumb+h), (100, 100, 100), 4)\n",
    "plt.imshow(thumbnail)\n",
    "plt.axis(\"off\")\n",
    "imageio.imwrite(f\"{image_id}_{MODEL.split('/')[-1]}_{mpp}_ROI_thumbnail.png\", thumbnail)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
